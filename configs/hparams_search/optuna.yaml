# @package _global_

# example hyperparameter optimization of some experiment with Optuna:
# python train.py -m hparams_search=optuna experiment=example

defaults:
  - override /hydra/launcher: ray
  - override /hydra/sweeper: optuna

hydra:

  mode: "MULTIRUN"

  launcher:
    ray:
      remote:
        num_cpus: 4
      init:
        local_mode: false

  sweeper:
    _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
    n_trials: 20
    n_jobs: 4
    direction: minimize

    sampler:
      _target_: optuna.samplers.TPESampler
      seed: 1234
      n_startup_trials: 10

    params:
      agent.optimizer.lr: interval(0.0001, 0.01)
      policy.Qnet.hidden_layers: choice([64, 64], [128, 128], [128, 128, 64], [256, 128, 64])
      policy.eps_decay: interval(0.9, 0.999)



